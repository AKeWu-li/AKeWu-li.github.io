<!DOCTYPE html><html class="hide-aside" lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>SplaTAM | 啊可恶的博客</title><meta name="author" content="啊可恶"><meta name="copyright" content="啊可恶"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="流程简化3DGS只使用了视图无关性颜色，并强制高斯是各向同性的。这意味着每个高斯仅由8个值参数化：3个为其RGB颜色，3个为其中心位置，1个为其半径，1个为其不透明度 可微渲染给定一组3D高斯和相机位姿，首先将所有高斯从前到后排序。 然后，通过将每个高斯的二维投影按顺序在像素空间进行alpha..."><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "SplaTAM",
  "url": "https://blog.liiz.top/2026/01/29/SplaTAM/",
  "image": "https://liiz-blog.oss-cn-shenzhen.aliyuncs.com/avatar.jpg",
  "datePublished": "2026-01-29T07:27:24.000Z",
  "dateModified": "2026-01-29T07:31:06.382Z",
  "author": [
    {
      "@type": "Person",
      "name": "啊可恶",
      "url": "https://blog.liiz.top"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.liiz.top/2026/01/29/SplaTAM/index.html"><link rel="preconnect" href="//cdnjs.cloudflare.com"><link rel="stylesheet" href="/css/index.css?v=5.5.3"><link rel="stylesheet" href="https://lib.baomitu.com/font-awesome/6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.css" media="print" onload='this.media="all"'><script>(() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'medium_zoom',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdnjs.cloudflare.com/ajax/libs/egjs-infinitegrid/4.12.0/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"SplaTAM",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><link rel="stylesheet" href="https://npm.elemecdn.com/lxgw-wenkai-screen-webfont@1.7.0/lxgwwenkaigbscreen.css"><link rel="stylesheet" href="https://unpkg.com/@firacode/cdn@latest/fired_code.css"><link rel="stylesheet" href="/css/welcome.css"><style>#footer,#footer-wrap{background:0 0!important;background-attachment:scroll!important;box-shadow:none!important}#footer-wrap::before,#footer::before{background:0 0!important;content:''!important}.article-sort-item::before{content:'\f35a'!important;font-family:'Font Awesome 6 Free'!important;font-weight:900!important;background:0 0!important;border:none!important;color:#000!important;font-size:20px!important;width:auto!important;height:auto!important;left:-40px!important;top:2px!important;transition:all .3s ease-in-out}.article-sort-title::before{content:'\f358'!important;font-family:'Font Awesome 6 Free'!important;font-weight:900!important;background:0 0!important;border:none!important;color:#000!important;font-size:24px!important;width:auto!important;height:auto!important;left:-10px!important;top:20px!important;transition:all .3s ease-in-out}.article-sort-item:hover::before,.article-sort-title:hover::before{transform:rotate(360deg);color:#00000f!important}.snackbar-container{background:#dfe9f3!important;background-color:#dfe9f3!important;border-radius:8px!important;display:flex!important;justify-content:center!important;align-items:center!important;bottom:0!important;left:20px!important;transform:none!important;transition:opacity .5s ease-in-out!important;min-width:180px!important;border:none!important}.snackbar-container[style*="opacity: 0"]{opacity:0!important;pointer-events:none!important}.snackbar-container p{font-family:'LXGW WenKai Screen',sans-serif!important;font-size:20px!important;font-weight:700!important;color:#00c2b5!important;margin:0!important;padding:6px 10px!important;text-align:center!important;line-height:1.5!important}.snackbar-container p::before{content:'\f058';font-family:'Font Awesome 6 Free'!important;font-weight:900!important;margin-right:8px!important;font-size:22px!important}@media screen and (max-width:768px){.snackbar-container{left:50%!important;transform:translateX(-50%)!important}}#page-header:not(.full_page){background:0 0!important;background-image:none!important;height:300px!important;box-shadow:none!important;border:none!important;margin-bottom:0!important}#page-header:not(.full_page)::before{background:0 0!important;box-shadow:none!important}#page-header:not(.full_page) #site-subtitle,#page-header:not(.full_page) #site-title,#page-header:not(.full_page) .page-title,#page-header:not(.full_page) .post-meta{color:#4c4948!important;text-shadow:none!important}#page-header:not(.full_page) #nav{z-index:9999!important;background:0 0!important;box-shadow:none!important}#page-header:not(.full_page) #nav #blog_name a,#page-header:not(.full_page) #nav #site-name{color:#333!important;text-shadow:none!important;font-weight:700!important}#page-header:not(.full_page) #nav .menus_item a{color:#333!important;text-shadow:none!important;font-weight:700!important}#page-header:not(.full_page) #nav #search-button{color:#333!important}#page-header:not(.full_page) #nav .toggle-menu{color:#333!important}#page-header:not(.full_page) #nav .menus_item a:hover{color:#00c2b5!important}body.home #nav #blog_name .site-name,body.home #nav #site-name{color:#fff!important;text-shadow:2px 2px 4px rgba(0,0,0,.6)!important}body.home #nav .menus_item .site-page,body.home #nav .menus_item i{color:#fff!important;text-shadow:1px 1px 2px rgba(0,0,0,.5)!important}body.home #nav #search-button{color:#fff!important;text-shadow:1px 1px 2px rgba(0,0,0,.5)!important}body:not(.home) #nav #blog_name .site-name,body:not(.home) #nav #site-name{color:#333!important;text-shadow:none!important;font-weight:900!important}body:not(.home) #nav .menus_item .site-page,body:not(.home) #nav .menus_item i{color:#333!important;text-shadow:none!important;font-weight:700!important}body:not(.home) #nav #search-button{color:#333!important}body:not(.home) #page-header .page-title{color:#333!important;text-shadow:none!important}body:not(.home) #post-info .post-title{color:#000!important;text-shadow:none!important;font-weight:700!important}body:not(.home) #post-info #post-meta,body:not(.home) #post-info .post-meta-separator,body:not(.home) #post-info i{color:#555!important;text-shadow:none!important}#nav #search-button:hover,#nav .site-name:hover,#nav .site-page:hover{color:#00c2b5!important}#page~#aside-content{display:none!important}.layout #page{float:none!important;margin:0 auto!important;width:90%!important;max-width:1200px!important;padding:40px!important}#nav #blog-info{display:none!important}#nav{justify-content:flex-end!important}#pagination.pagination-post .cover{background:linear-gradient(to top,#dfe9f3 0,#dfe9f3 100%)!important;opacity:1!important}#pagination.pagination-post .cover::after,#pagination.pagination-post .cover::before,#pagination.pagination-post .next-post>a::after,#pagination.pagination-post .next-post>a::before,#pagination.pagination-post .prev-post>a::after,#pagination.pagination-post .prev-post>a::before{background:0 0!important;background-image:none!important;display:none!important;opacity:0!important;content:none!important}#pagination.pagination-post .info-item-1,#pagination.pagination-post .info-item-2{color:#00c2b5!important;text-shadow:none!important;font-weight:700!important}#pagination.pagination-post:hover .info-item-1,#pagination.pagination-post:hover .info-item-2{color:#000!important}</style><script src="https://npm.elemecdn.com/typed.js@2.0.12/lib/typed.min.js"></script><script src="/js/custom.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body><div class="bg-animation" id="web_bg" style="background:linear-gradient(to top,#dfe9f3 0,#fff 100%)"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://liiz-blog.oss-cn-shenzhen.aliyuncs.com/avatar.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background:linear-gradient(to top,#dfe9f3 0,#fff 100%)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">啊可恶的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">SplaTAM</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span> 返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">SplaTAM</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-29T07:27:24.000Z" title="发表于 2026-01-29 15:27:24">2026-01-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-29T07:31:06.382Z" title="更新于 2026-01-29 15:31:06">2026-01-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/3D-Reconstruction/">3D Reconstruction</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h3 id="简化3DGS"><a href="#简化3DGS" class="headerlink" title="简化3DGS"></a>简化3DGS</h3><p>只使用了视图无关性颜色，并强制高斯是各向同性的。这意味着每个高斯仅由8个值参数化：3个为其RGB颜色，3个为其中心位置，1个为其半径，1个为其不透明度</p><h3 id="可微渲染"><a href="#可微渲染" class="headerlink" title="可微渲染"></a>可微渲染</h3><p>给定一组3D高斯和相机位姿，首先将所有高斯从前到后排序。 然后，通过将每个高斯的二维投影按顺序在像素空间进行alpha组合，可以有效地渲染RGB图像</p><h3 id="SLAM系统"><a href="#SLAM系统" class="headerlink" title="SLAM系统"></a>SLAM系统</h3><ul><li><p>初始化</p><ul><li>对于第一帧，对于每个像素，我们添加一个新的高斯，其颜色为该像素的颜色，中心在该像素深度的未投影位置，不透明度为0.5，投影到二维图像上的半径等于一像素半径，用深度除以焦距得到</li></ul></li><li><p>相机追踪</p><ul><li>相机参数初始化 $$ Et+1 = Et + (Et - Et-1) $$</li><li>基于梯度的优化迭代更新相机位姿，通过差分渲染RGB，深度和剪影图，并更新相机参数，以最小化以下损失，同时保持高斯参数固定</li><li>只使用我们渲染的可见性剪影来应用从地图的优化部分渲染的像素的损失，该剪影捕捉了地图的认知不确定性。这对于跟踪新的相机姿态非常重要，因为通常新的帧包含新的信息，而这些信息在我们的地图中尚未被捕获或很好地优化。如果一个像素没有真值深度，L1损失也为0</li></ul></li><li><p>致密化</p><ul><li>在跟踪之后，我们对这一帧的相机位姿有一个准确的估计，并且通过一幅深度图像，我们对场景中的高斯应该在哪里有一个很好的估计。但是，我们不希望在当前高斯已经精确表示场景几何的情况下添加高斯。因此，我们创建了一个致密化掩膜来确定哪些像素应该被致密化</li></ul></li><li><p>高斯地图更新</p><ul><li>这一步是在已知估计的在线相机姿态集合的情况下，更新3D高斯映射的参数。这又是通过可微渲染和基于梯度的优化来完成的，然而与跟踪不同的是，在这种设置中，相机的姿态是固定的，并且高斯的参数是更新的</li><li>这相当于将辐射场拟合到已知姿态的图像的”经典”问题。然而，我们做了两个重要的修改。而不是从头开始，我们从最近构建的地图中热启动优化。我们也没有对所有以前的(关键)帧进行优化，而是选择可能影响新添加的高斯的帧。我们将每第n帧保存为一个关键帧，并选择k个关键帧进行优化，包括当前帧、最近关键帧以及与当前帧重叠度最高的前k-2个关键帧。重叠度通过取当前帧深度图的点云，并确定每个关键帧视锥体内部的点数来确定</li><li>这个阶段优化了与跟踪过程中类似的损失，除了我们没有使用轮廓掩模，因为我们想在所有像素上优化。此外，我们在RGB渲染中添加了SSIM损失，并删除了无用的高斯，这些高斯具有接近0的不透明度或太大</li></ul></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>首先对3DGS的参数进行简化，每个高斯仅8个参数（3个为其RGB颜色，3个为其中心位置，1个为其半径，1个为其不透明度），对第一帧的每个像素添加一个高斯；<br>接下来就是一个循环的过程：<br>1.输入是上一时刻建好的高斯模型和相机渲染出的照片，以及此刻相机拍出的图片（彩色图+深度图）<br>2.相机追踪<br>先对相机参数进行初始化（通过上一时刻与上上时刻相机位姿的关系和上一时刻的位姿得出这一时刻的相机参数），然后通过计算出来的位姿渲染出照片。<br>将这个模型和输入的相机拍出来的图片进行遮罩操作，splatam只在已知区域（即黑色区域）进行计算（因为它知道白色区域是新东西，如果强行对比会导致定位跑偏）。<strong>（Gemini认为白色是已知区域，黑色是未知区域，因为S(p)=1表示白色，而S(p)=0表示黑色）</strong><br>注：这里的$Sil$是可见度（专业术语是Silhouette，轮廓/不透明度累积图。这是高斯球的一个参数，如果某个像素位置上有很多高斯球，$Sil \approx 1$；如果某个像素位置是空的，$Sil \approx 0$），$\lambda$是阈值（论文中设置为0.99），因此，$(Sil &gt; \lambda)$就是只有那些地图里非常确信存在的、实实在在的区域，才算数（为1）；半透明的、没探索过的区域，统统不算（为0）。故$(Sil &gt; \lambda)$乘以 $F_t$ 和 Render就相当于遮罩操作。<br>然后调整相机位置 $E’$，让渲染出来的图和真实照片 $F_t$ 在已知区域进行对比，反向优化相机的位姿，最终得到精确的位姿。这里的公式为（这里的深度（几何信息）对于定位比颜色更重要权值更高（颜色容易受光照影响））：$$E_t = \text{argmin} | (Sil &gt; \lambda) * (\text{Render}(G_{t-1}, E’) - F_t) |_1$$</p><p>3.高斯致密化<br>先根据上一步得到的精确位姿对上一时刻渲染出的高斯模型上渲染出一个图片，然后做一个密集化掩码，标记出“需要添加新点”的区域。这里密集化掩码的公式为：$$M(p) = (S(p) &lt; 0.5) + (D_{GT}(p) &lt; D(p))(L_1(D(p)) &gt; \lambda \text{MDE})$$<br>注：<br>1）$M(p)$ 是 Densification Mask（致密化掩膜），如果某个像素 $p$ 计算结果为 1 ，系统就会在这里生成新的高斯球。<br>2）$S(p)$表示不透明度。如果 $S(p) \approx 1$：说明这里有很厚实的墙或物体。如果 $S(p) \approx 0$：说明这里是空气，或者还没建过图。<br>3）$D_{GT}(p)$：真实深度（Ground Truth）。无人机刚拍到的深度图。$D(p)$：渲染深度（Rendered Depth）。比如真实地图测得前方 1 米处有东西，旧地图认为前方 3 米处才是墙，1米 &lt; 3米，说明真实世界里，有个未知的东西在前方1米处（而且不是墙）。<br>4）$L_1(D(p))$：深度误差，即 $|D_{GT} - D_{Render}|$。$\text{MDE}$：中位数深度误差 (Median Depth Error)，这是当前这一帧画面的平均误差水平。$\lambda$：敏感度系数。论文中设为 50 。因此这里公式的意思是只有当这个点的深度误差，比全图中位数误差还要大 50 倍时，我才承认它是真的“新物体”，而不是传感器抖动，防止因为传感器的一点点误差就疯狂加点。</p><p>然后添加高斯点（即红色区域）。论文中公式如下：$$G_t^d = \text{Densify}(G_{t-1}, F_t, E_t, Sil)$$<br>注：在函数 Densify 内部，首先利用上一公式筛选像素，遍历 $F_t$ 的每一个像素，如果是空的或有新物体则选中该像素；然后利用相机内参 $K$ 和位姿 $E_t$ 计算 3D 坐标 $\mu$（从相机位置 $E_t$ 出发，沿着像素 $(u,v)$ 的方向，射出一道光，飞行 $D_{GT}$（真实深度）这么远，那个落点就是新高斯球的球心）；然后初始化高斯球的属性，颜色 ($c$)直接取像素的 RGB 颜色，大小 ($r$)就根据深度估算（离得越远，像素代表的物理范围越大，球半径 $r = \frac{D_{GT}}{f}$（深度除以焦距）），透明度 ($o$)会初始化为一个中间值（例如 0.5），表示“我不确定我是不是实体，先放这里，等下一步优化来决定去留”。<br>4.地图更新<br>先根据精确位姿对上一步得到的粗略高斯模型渲染出新图片，<br>然后利用可微渲染，同时调整新点和旧点的参数（颜色、位置、大小、透明度），让它们渲染出来的图像与真实图像无缝衔接（也就是通过图片的对比反向优化各高斯元参数），这里公式如下：$$G_t = \text{argmin} \sum | \text{Render}(G’, E_k) - F_k |_1$$<br>注：这里不仅使用当前帧，还会选取 $k$ 个关键帧 (Keyframes) 一起参与优化，包括当前帧 + 最近的一个关键帧 + $k-2$ 个视锥重叠度最高的历史关键帧。<br>最终得到新的高斯模型，用作下一时刻的输入。</p><hr><h3 id="公式-1：3D-高斯球的定义-The-Atom"><a href="#公式-1：3D-高斯球的定义-The-Atom" class="headerlink" title="公式 1：3D 高斯球的定义 (The Atom)"></a><strong>公式 1：3D 高斯球的定义 (The Atom)</strong></h3><p>$$f(x) = o \cdot \exp\left(-\frac{||x - \mu||^2}{2r^2}\right)$$</p><p><strong>含义</strong>：这是 SplaTAM 中<strong>最基本的单元</strong>。</p><p><strong>简化版高斯</strong>：注意，标准 3DGS 使用各向异性（椭球）的高斯函数，但这篇论文为了 SLAM 的速度和稳定性，将其简化为 <strong>各向同性（Isotropic）</strong>，也就是正球体 。</p><p><strong>参数</strong>：</p><ul><li><p>(Mu)：球心的 3D 位置 。</p></li><li><p>(Radius)：球的半径（控制它的大小）。</p></li><li><p>(Opacity)：不透明度（0~1），控制它有多“实”。</p></li></ul><p><strong>物理意义</strong>：这个公式计算的是空间中任意一点 受到的该高斯球的<strong>影响值（密度/贡献度）</strong>。离球心$\mu$ 越近，值越大；越远，值按指数衰减。</p><hr><h3 id="公式-2：可微渲染-颜色-The-Painter"><a href="#公式-2：可微渲染-颜色-The-Painter" class="headerlink" title="公式 2：可微渲染 - 颜色 (The Painter)"></a><strong>公式 2：可微渲染 - 颜色 (The Painter)</strong></h3><p>$$C(p) = \sum_{i=1}^{n} c_i f_i(p) \prod_{j=1}^{i-1} (1 - f_j(p))$$</p><p><strong>含义</strong>：这是经典的<strong>体积渲染公式（Volumetric Rendering）</strong>，也就是 alpha-blending（透明度混合）。</p><p><strong>如何计算一个像素 的颜色？</strong></p><ol><li>从相机发射一条光线穿过该像素。</li><li>光线会穿过一串高斯球（排好序：$1, 2, …, n$）。</li><li>$c_i f_i(p)$：第 $i$ 个球的颜色 $c_i$ 乘以它在该位置的密度 $f_i$。</li><li>$\prod (1 - f_j(p))$：这是透射率（Transmittance）。意思是你虽然有颜色，但你的可见度要取决于挡在你前面的球有多透明。如果前面的球完全不透明（$f=1$），后面这一项就变成 0，你就看不见了。</li></ol><p><strong>作用</strong>：生成 RGB 图像，用于和真实照片对比算 Loss。</p><hr><h3 id="公式-3：3D-到-2D-的投影-The-Lens"><a href="#公式-3：3D-到-2D-的投影-The-Lens" class="headerlink" title="公式 3：3D 到 2D 的投影 (The Lens)"></a><strong>公式 3：3D 到 2D 的投影 (The Lens)</strong></h3><p>$$\mu^{2D} = K \frac{E_t \mu}{d}, \quad r^{2D} = \frac{f r}{d}$$</p><p><strong>含义</strong>：把 3D 世界里的球，拍扁到 2D 屏幕上。</p><p><strong>$\mu^{2D}$ (屏幕位置)：</strong></p><ul><li>$E_t \mu$：先把世界坐标转为相机坐标。</li><li>除以 $d$（深度）：近大远小。</li><li>乘 $K$（内参）：映射到像素坐标系。</li></ul><p><strong>$r^{2D}$ (屏幕半径)：</strong></p><ul><li>这是高斯球在屏幕上的<strong>投影半径</strong>。</li><li>$f$ 是焦距，$r$ 是物理半径，$d$ 是深度。</li><li><strong>物理规律</strong>：物体离相机越远（ 越大），在屏幕上看起来就越小。</li></ul><hr><h3 id="公式-4：可微渲染-深度-The-Ruler"><a href="#公式-4：可微渲染-深度-The-Ruler" class="headerlink" title="公式 4：可微渲染 - 深度 (The Ruler)"></a><strong>公式 4：可微渲染 - 深度 (The Ruler)</strong></h3><p>$$D(p) = \sum_{i=1}^{n} d_i f_i(p) \prod_{j=1}^{i-1} (1 - f_j(p))$$</p><p><strong>含义</strong>：这跟公式 2 的结构一模一样，只不过把累积的对象从“颜色 $c_i$”换成了“深度 $d_i$”。<br><strong>深度渲染</strong>：它计算的是这光线碰到的所有物体的<strong>加权平均深度</strong>。<br><strong>作用</strong>：生成<strong>渲染深度图</strong>。这是 SplaTAM 的核心优势，它能直接针对深度误差进行优化（Geometric Loss），而不仅仅是颜色误差。</p><hr><h3 id="公式-5：轮廓掩膜-可见度-The-Scout"><a href="#公式-5：轮廓掩膜-可见度-The-Scout" class="headerlink" title="公式 5：轮廓掩膜 / 可见度 (The Scout)"></a><strong>公式 5：轮廓掩膜 / 可见度 (The Scout)</strong></h3><p>$$S(p) = \sum_{i=1}^{n} f_i(p) \prod_{j=1}^{i-1} (1 - f_j(p))$$</p><p><strong>含义</strong>：这就是你要的 <strong>Silhouette Mask</strong>。<br><strong>结构</strong>：依然是体积渲染公式，但去掉了颜色项和深度项，只累积<strong>不透明度（Opacity/Density）</strong>。<br><strong>结果解读</strong>：</p><ul><li>$S(p) \approx 1$：光线最终撞上了厚实的东西（墙壁）。$\rightarrow$ 已知区域。</li><li>$S(p) \approx 0$：光线穿透了所有东西也没遇到阻碍（看向虚空）。$\rightarrow$ 未知区域。</li></ul><p><strong>作用</strong>：区分“有地图的地方”和“没地图的地方”，用于过滤 Loss。</p><hr><h3 id="公式-6：初始化半径-The-Seed"><a href="#公式-6：初始化半径-The-Seed" class="headerlink" title="公式 6：初始化半径 (The Seed)"></a><strong>公式 6：初始化半径 (The Seed)</strong></h3><p>$$r = \frac{D_{GT}}{f}$$</p><p><strong>含义</strong>：当我们要在某个位置新生成一个高斯球时，它应该多大？<br><strong>逻辑</strong>：根据公式 3，我们希望新生成的球投影到屏幕上时，<strong>半径刚好对应 1 个像素</strong>。</p><ul><li>令公式 3 中的 $r^{2D} = 1$。</li><li>推导出 $1 = \frac{f \cdot r}{d}$。</li><li>得到 $r = \frac{d}{f}$（这里用 $D_{GT}$ 代表深度）。</li></ul><p><strong>作用</strong>：防止新加的点太大（导致模糊）或太小（导致空洞/Aliasing）。</p><hr><h3 id="公式-8：相机追踪损失函数-The-Judge"><a href="#公式-8：相机追踪损失函数-The-Judge" class="headerlink" title="公式 8：相机追踪损失函数 (The Judge)"></a><strong>公式 8：相机追踪损失函数 (The Judge)</strong></h3><p>$$L_t = \sum_{p} (S(p) &gt; 0.99) \cdot (L_1(D(p)) + 0.5 L_1(C(p)))$$</p><p><strong>含义</strong>：这是 Step 1 (Camera Tracking) 用来优化相机位姿的 <strong>Loss Function</strong>。<br><strong>组成部分拆解</strong>：</p><ul><li>$L_1(D(p))$：深度误差。渲染深度 vs 真实深度。这是定位最主要的依据。</li><li>$L_1(C(p))$：颜色误差。渲染颜色 vs 真实照片。</li><li>$0.5$：权重。作者经验发现颜色误差不如深度误差可靠（容易受光照影响），所以打个五折。</li><li>$(S(p) &gt; 0.99)$：核心掩膜。只有在轮廓图显示“这里非常实 ($&gt;0.99$)”的像素，才计算误差。如果 $S(p) &lt; 0.99$，说明这里可能是边界或者未探索区域，渲染结果不可信，直接忽略，不计入 Loss。</li></ul><hr><p>这一套公式环环相扣：用 <strong>Eq 1</strong> 定义球，用 <strong>Eq 2/4/5</strong> 渲染出图像，用 <strong>Eq 8</strong> 对比图像算出位置，最后用 <strong>Eq 6</strong> 初始化新球来修补误差。这构成了 SplaTAM 的数学闭环。</p><hr><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="scripts-splatam-py"><a href="#scripts-splatam-py" class="headerlink" title="scripts/splatam.py"></a>scripts/splatam.py</h3><h4 id="get-loss"><a href="#get-loss" class="headerlink" title="get_loss()"></a>get_loss()</h4><p>它有三个步骤：投影（Projection）、光栅化（Rasterization） 和 评分（Loss Calculation）</p><p>一、投影</p><ul><li>输入是世界坐标系下的几十万个高斯球，输出是相机平面上的 2D 椭圆（因为splatam里面的高斯球是各向同性，在 3D 空间它是正球体，投影到 2D 平面它永远是一个圆，因此这里其实时园）</li><li>如果一个球跑到了相机屁股后面（Z &lt; 0），或者跑出了屏幕边缘，直接扔掉，不参与计算</li></ul><p>首先利用当前的相机位姿 (curr_data[‘cam’])，把所有高斯球的中心点 means3D 从世界坐标搬到相机坐标系下；<br>然后通过一个雅可比矩阵（Jacobian），把3D 高斯球（ 3x3 的协方差矩阵）投影到 2D 图像平面上，变成一个 2x2 的 2D 协方差矩阵</p><p>二、光栅化</p><p>首先把所有在屏幕内的高斯球，按照深度（Depth）从远到近排序，然后遍历每个像素，从近到远（或从远到近）累加颜色的贡献，然后进行渲染，渲染出深度图和颜色图</p><p>三、评分</p><p>和真实数据计算误差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 颜色误差 (L1 Loss)</span></span><br><span class="line"><span class="comment"># 看看画出来的图和照片差多少</span></span><br><span class="line">loss_im = torch.<span class="built_in">abs</span>(gt_im - render_im).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 深度误差 (L1 Depth Loss)</span></span><br><span class="line"><span class="comment"># SplaTAM 的核心：不仅要看着像，几何位置也得对！</span></span><br><span class="line">loss_depth = torch.<span class="built_in">abs</span>(gt_depth - render_depth).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 总分</span></span><br><span class="line">loss = w_im * loss_im + w_depth * loss_depth</span><br></pre></td></tr></table></figure><h5 id="transform-to-frame"><a href="#transform-to-frame" class="headerlink" title="transform_to_frame()"></a>transform_to_frame()</h5><p>作用：1）梯度控制开关，如gaussians_grad=False, camera_grad=True就是当反向传播的时候，只有相机的位置会更新，这样就可以再追踪阶段计算相机的精确位姿；2）时间切片与位姿提取：transform_to_frame 根据传入的 iter_time_idx（时间戳），从巨大的轨迹数组中提取出当前这一帧对应的旋转（Rotation）和平移（Translation），还会把存储的四元数（Quaternion）转换为渲染器需要的旋转矩阵，其中params 字典里存储的是所有帧的相机轨迹。函数的输出为打包好的 transformed_gaussians，里面包含：当前时刻的相机位姿（带梯度或不带）、当前所有的高斯球（带梯度或不带），这个包会直接喂给 Renderer 去生成图像。</p><p><strong>第一帧时打印：</strong></p><hr><p>🔍 DEBUG: params (总仓库)</p><p>[Key] means3D [Shape] [255190, 3]</p><p>[Key] rgb_colors [Shape] [255190, 3]</p><p>[Key] unnorm_rotations [Shape] [255190, 4]</p><p>[Key] logit_opacities [Shape] [255190, 1]</p><p>[Key] log_scales [Shape] [255190, 1]</p><p>[Key] cam_unnorm_rots [Shape] [1, 4, 592]</p><p>[Key] cam_trans [Shape] [1, 3, 592]</p><p>🔍 DEBUG: transformed_gaussians (当前帧数据包)</p><p>[Key] means3D [Shape] [255190, 3]</p><p>[Key] unnorm_rotations [Shape] [255190, 4]</p><hr><p><strong>各参数解释：</strong><br>255,190：地图里目前总共有 255,190 个高斯球。系统把第 0 帧图片里每一个有有效深度的像素，都变成了一个 3D 高斯球。图片分辨率是 640x480 = 307,200 像素，其中大约有 5万个像素可能是无效深度（太远或太近），剩下的 255,190 个像素被成功转换成了第一批高斯球。<br>592：TUM 数据集序列（freiburg1_desk）总共有 592 帧。</p><ul><li>means3D: [255190, 3]<ul><li>位置，即x、y、z坐标</li></ul></li><li>rgb_colors: [255190, 3]<ul><li>颜色，即R、G、B参数</li></ul></li><li>unnorm_rotations: [255190, 4]<ul><li>姿态，旋转四元数(w, x, y, z)</li><li>注：未归一化</li></ul></li><li>logit_opacities：[255190, 1]<ul><li>不透明度，值大 $\to$ 实心墙壁，值小 $\to$ 稀薄的烟雾（或者噪声）</li><li>$o = \text{Sigmoid}(\text{logit_opacities})$。我们在 params 里存 logit 值（可以是 $-\infty$ 到 $+\infty$），算的时候过一下 Sigmoid 函数就变成了 $0 \sim 1$</li></ul></li><li>log_scales: [255190, 1]<ul><li>半径，论文里为了快，把球简化成了正球体，只有一个半径参数 $r$</li><li>注：这里存储的是半径的对数。因为优化器调整参数时可能会把数字减成负数，故存 log(r)，取出来用的时候做 exp(log(r))，就能保证半径永远是正数</li></ul></li><li>cam_unnorm_rots：[1, 4, 592]<ul><li>存的是每一帧相机的 旋转（四元数）</li></ul></li><li>cam_trans: [1, 3, 592]<ul><li>Batch Size，这里永远是 1</li><li>相机的 (x, y, z) 坐标</li><li>数据集序列共592帧</li><li>存的是每一帧相机在世界坐标系下的 平移 $(x, y, z)$</li></ul></li></ul><p>具体例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;means3D&#x27;</span>: Parameter containing:</span><br><span class="line">tensor([[-<span class="number">0.9017</span>, -<span class="number">0.7259</span>,  <span class="number">1.4686</span>],</span><br><span class="line">        [-<span class="number">0.8988</span>, -<span class="number">0.7259</span>,  <span class="number">1.4686</span>],</span><br><span class="line">        [-<span class="number">0.5105</span>, -<span class="number">0.3596</span>,  <span class="number">0.8394</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [ <span class="number">0.7847</span>,  <span class="number">0.6526</span>,  <span class="number">1.5068</span>],</span><br><span class="line">        [ <span class="number">0.7876</span>,  <span class="number">0.6526</span>,  <span class="number">1.5068</span>],</span><br><span class="line">        [ <span class="number">0.7905</span>,  <span class="number">0.6526</span>,  <span class="number">1.5068</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>), <span class="string">&#x27;rgb_colors&#x27;</span>: Parameter containing:</span><br><span class="line">tensor([[<span class="number">0.2353</span>, <span class="number">0.1176</span>, <span class="number">0.1608</span>],</span><br><span class="line">        [<span class="number">0.2353</span>, <span class="number">0.1176</span>, <span class="number">0.1176</span>],</span><br><span class="line">        [<span class="number">0.4824</span>, <span class="number">0.4118</span>, <span class="number">0.5137</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [<span class="number">0.0510</span>, <span class="number">0.0157</span>, <span class="number">0.0078</span>],</span><br><span class="line">        [<span class="number">0.0627</span>, <span class="number">0.0196</span>, <span class="number">0.0078</span>],</span><br><span class="line">        [<span class="number">0.0549</span>, <span class="number">0.0118</span>, <span class="number">0.0118</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>), <span class="string">&#x27;unnorm_rotations&#x27;</span>: Parameter containing:</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>), <span class="string">&#x27;logit_opacities&#x27;</span>: Parameter containing:</span><br><span class="line">tensor([[<span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [<span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>), <span class="string">&#x27;log_scales&#x27;</span>: Parameter containing:</span><br><span class="line">tensor([[-<span class="number">5.8635</span>],</span><br><span class="line">        [-<span class="number">5.8635</span>],</span><br><span class="line">        [-<span class="number">6.4229</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [-<span class="number">5.8379</span>],</span><br><span class="line">        [-<span class="number">5.8379</span>],</span><br><span class="line">        [-<span class="number">5.8379</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>), <span class="string">&#x27;cam_unnorm_rots&#x27;</span>: Parameter containing:</span><br><span class="line">tensor([[[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]]], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>), <span class="string">&#x27;cam_trans&#x27;</span>: Parameter containing:</span><br><span class="line">tensor([[[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]]], device=<span class="string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="literal">True</span>)&#125;</span><br></pre></td></tr></table></figure><p><strong>疑问：</strong><br>1）为什么 transformed_gaussians 要存 25万个球？<br>答：transform_to_frame 只是把数据从仓库里拿出来，准备喂给 GPU。<br>Python 把 25万个球全部扔给 CUDA 渲染器（Renderer）。渲染器内部 会自动判断哪些球在相机视野里，哪些在背后。<br>在 Python 层面手动算“哪个球在视野里”太慢了，不如直接全部扔给 GPU 算。所以 transformed_gaussians 里依然保留了所有球。<br>2）为何它只存了“位置”和“姿态”，把“颜色”和“半径”弄丢了<br>答：因为这只是个“中转包”，只有 位置 (means3D) 和 旋转 (rotations) 会受到相机移动的影响，所以需要重点处理，而后面会进行组装，从 params (总仓库) 里直接拿颜色、半径、不透明度（因为这些属性不管相机怎么动，它们本身是不变的，不需要变换坐标系）</p><h3 id="恒速运动模型-initialize-camera-pose-函数"><a href="#恒速运动模型-initialize-camera-pose-函数" class="headerlink" title="恒速运动模型(initialize_camera_pose 函数)"></a>恒速运动模型(initialize_camera_pose 函数)</h3><p>追踪部分，根据过去两帧的运动趋势，计算出相机的初始位姿，对应公式：<br>$$Pose_{t} = Pose_{t-1} + (Pose_{t-1} - Pose_{t-2})$$</p><h4 id="平移"><a href="#平移" class="headerlink" title="平移"></a>平移</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">prev_tran1 = params[<span class="string">&#x27;cam_trans&#x27;</span>][..., curr_time_idx-<span class="number">1</span>].detach() <span class="comment"># 位置 P_&#123;t-1&#125;</span></span><br><span class="line">prev_tran2 = params[<span class="string">&#x27;cam_trans&#x27;</span>][..., curr_time_idx-<span class="number">2</span>].detach() <span class="comment"># 位置 P_&#123;t-2&#125;</span></span><br><span class="line"><span class="comment"># 预测当前位置 P_t</span></span><br><span class="line">new_tran = prev_tran1 + (prev_tran1 - prev_tran2)</span><br></pre></td></tr></table></figure><p>解释：params[‘cam_trans’] 的形状是 [1, 3, 592]，因此[…, curr_time_idx-1]的意思是保持前面所有维度（Batch 和 xyz）不变，只取最后一个维度（时间轴）上的第 curr_time_idx-1 帧的数据。.detach()的意思是<strong>切断梯度流</strong>，因为不需要做反向传播。</p><h4 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取出并归一化四元数</span></span><br><span class="line">prev_rot1 = F.normalize(params[<span class="string">&#x27;cam_unnorm_rots&#x27;</span>][..., curr_time_idx-<span class="number">1</span>].detach()) <span class="comment"># Q_&#123;t-1&#125;</span></span><br><span class="line">prev_rot2 = F.normalize(params[<span class="string">&#x27;cam_unnorm_rots&#x27;</span>][..., curr_time_idx-<span class="number">2</span>].detach()) <span class="comment"># Q_&#123;t-2&#125;</span></span><br><span class="line"><span class="comment"># 线性外推并重新归一化</span></span><br><span class="line">new_rot = F.normalize(prev_rot1 + (prev_rot1 - prev_rot2))</span><br></pre></td></tr></table></figure><h3 id="slam-external-py-prune-gaussians"><a href="#slam-external-py-prune-gaussians" class="headerlink" title="slam_external.py/prune_gaussians()"></a>slam_external.py/prune_gaussians()</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>在建图（Mapping）优化的过程中，定期把那些没用的或者错误的高斯球清理掉，以保持地图的干净和显存的高效。其主要是定时剪枝、按条件筛选、重置透明度。</p><h4 id="定时剪枝"><a href="#定时剪枝" class="headerlink" title="定时剪枝"></a>定时剪枝</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">iter</span> &lt;= prune_dict[<span class="string">&#x27;stop_after&#x27;</span>]:</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">iter</span> &gt;= prune_dict[<span class="string">&#x27;start_after&#x27;</span>]) <span class="keyword">and</span> (<span class="built_in">iter</span> % prune_dict[<span class="string">&#x27;prune_every&#x27;</span>] == <span class="number">0</span>):</span><br></pre></td></tr></table></figure><ul><li><p>它只在迭代次数处于 start_after 和 stop_after 之间进行。</p></li><li><p>每隔 prune_every (20) 次迭代才执行一次，避免频繁操作拖慢速度。</p></li></ul><h4 id="按条件筛选"><a href="#按条件筛选" class="headerlink" title="按条件筛选"></a>按条件筛选</h4><p>条件一:透明度太低</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">iter</span> == prune_dict[<span class="string">&#x27;stop_after&#x27;</span>]:</span><br><span class="line">    remove_threshold = prune_dict[<span class="string">&#x27;final_removal_opacity_threshold&#x27;</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    remove_threshold = prune_dict[<span class="string">&#x27;removal_opacity_threshold&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算真实透明度并判断</span></span><br><span class="line">to_remove = (torch.sigmoid(params[<span class="string">&#x27;logit_opacities&#x27;</span>]) &lt; remove_threshold).squeeze()</span><br></pre></td></tr></table></figure><p>解释：logit_opacities 是存储的参数，通过 sigmoid 变成 0~1 的真实透明度 ， remove_threshold 是设置的阈值 0.005</p><p>条件二：太大了（遮挡视线）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">iter</span> &gt;= prune_dict[<span class="string">&#x27;remove_big_after&#x27;</span>]:</span><br><span class="line">    <span class="comment"># 计算真实半径，判断是否超过场景半径的 10%</span></span><br><span class="line">    big_points_ws = torch.exp(params[<span class="string">&#x27;log_scales&#x27;</span>]).<span class="built_in">max</span>(dim=<span class="number">1</span>).values &gt; <span class="number">0.1</span> * variables[<span class="string">&#x27;scene_radius&#x27;</span>]</span><br><span class="line">    to_remove = torch.logical_or(to_remove, big_points_ws)</span><br></pre></td></tr></table></figure><p>解释：exp(log_scales) 还原出真实半径，如果一个球膨胀得巨大（超过整个场景半径的 10%），通常是因为优化失败产生的伪影（Artifact），就像贴在镜头前的一个大光斑。这种球会严重干扰后续建图</p><p>最后执行删除操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">params, variables = remove_points(to_remove, params, variables, optimizer)</span><br></pre></td></tr></table></figure><h4 id="重置透明度"><a href="#重置透明度" class="headerlink" title="重置透明度"></a>重置透明度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">iter</span> &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">iter</span> % prune_dict[<span class="string">&#x27;reset_opacities_every&#x27;</span>] == <span class="number">0</span> <span class="keyword">and</span> prune_dict[<span class="string">&#x27;reset_opacities&#x27;</span>]:</span><br><span class="line">    new_params = &#123;<span class="string">&#x27;logit_opacities&#x27;</span>: inverse_sigmoid(torch.ones_like(params[<span class="string">&#x27;logit_opacities&#x27;</span>]) * <span class="number">0.01</span>)&#125;</span><br><span class="line">    params = update_params_and_optimizer(new_params, params, optimizer)</span><br></pre></td></tr></table></figure><p>解释：每隔一段时间，强制把所有高斯球的透明度都设为极低的值（0.01），其目的是</p><ul><li><p>如果一个球是真的墙壁或物体，在接下来的几次迭代中，为了减小 Loss，梯度会迅速把它重新“拉黑”（变不透明）。</p></li><li><p>如果一个球是早期的噪声或误判，重置后它就再也“站不起来”了（一直保持透明），然后在下一次剪枝中被彻底删掉。</p></li><li><p>这能有效防止陷入局部最优，去掉那些“僵尸”高斯球。</p></li></ul><h3 id="slam-external-py-keyframe-selection-overlap"><a href="#slam-external-py-keyframe-selection-overlap" class="headerlink" title="slam_external.py/keyframe_selection_overlap"></a>slam_external.py/keyframe_selection_overlap</h3><h4 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h4><p>在地图更新时使用挑选的关键帧的图像与渲染出的图像对比，进行反向优化，这个函数正是为了挑选关键帧</p><h4 id="首先从当前帧里随机挑了一些“探针”点"><a href="#首先从当前帧里随机挑了一些“探针”点" class="headerlink" title="首先从当前帧里随机挑了一些“探针”点"></a>首先从当前帧里随机挑了一些“探针”点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 找到所有有有效深度（&gt;0）的像素坐标</span></span><br><span class="line">valid_depth_indices = torch.where(gt_depth[<span class="number">0</span>] &gt; <span class="number">0</span>)</span><br><span class="line">valid_depth_indices = torch.stack(valid_depth_indices, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 随机抽取 pixels (默认1600) 个点作为代表</span></span><br><span class="line">indices = torch.randint(valid_depth_indices.shape[<span class="number">0</span>], (pixels,))</span><br><span class="line">sampled_indices = valid_depth_indices[indices]</span><br></pre></td></tr></table></figure><h4 id="把这些选出来的-2D-像素点，变成-3D-世界坐标点"><a href="#把这些选出来的-2D-像素点，变成-3D-世界坐标点" class="headerlink" title="把这些选出来的 2D 像素点，变成 3D 世界坐标点"></a>把这些选出来的 2D 像素点，变成 3D 世界坐标点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把 2D 像素 + 深度 -&gt; 3D 世界坐标点 (pts)</span></span><br><span class="line">pts = get_pointcloud(gt_depth, intrinsics, w2c, sampled_indices)</span><br></pre></td></tr></table></figure><h4 id="拿着这些-3D-世界点，去试探每一个历史关键帧，看看历史帧的相机能看到多少点"><a href="#拿着这些-3D-世界点，去试探每一个历史关键帧，看看历史帧的相机能看到多少点" class="headerlink" title="拿着这些 3D 世界点，去试探每一个历史关键帧，看看历史帧的相机能看到多少点"></a>拿着这些 3D 世界点，去试探每一个历史关键帧，看看历史帧的相机能看到多少点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> keyframeid, keyframe <span class="keyword">in</span> <span class="built_in">enumerate</span>(keyframe_list):</span><br><span class="line">    <span class="comment"># 1. 取出历史帧的位姿 (World-to-Camera)</span></span><br><span class="line">    est_w2c = keyframe[<span class="string">&#x27;est_w2c&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 把世界点转到历史帧的相机坐标系下</span></span><br><span class="line">    pts4 = torch.cat([pts, torch.ones_like(pts[:, :<span class="number">1</span>])], dim=<span class="number">1</span>) <span class="comment"># 变成齐次坐标</span></span><br><span class="line">    transformed_pts = (est_w2c @ pts4.T).T[:, :<span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 再投影到历史帧的 2D 图像平面</span></span><br><span class="line">    points_2d = torch.matmul(intrinsics, transformed_pts.transpose(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># ... (透视除法 /z) ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 检查点是否在图像范围内 (在屏幕内且在相机前方)</span></span><br><span class="line">    edge = <span class="number">20</span> <span class="comment"># 边缘留一点余量</span></span><br><span class="line">    mask = (projected_pts[:, <span class="number">0</span>] &lt; width-edge) * ... <span class="comment"># x, y 均在图像范围内</span></span><br><span class="line">    mask = mask &amp; (points_z[:, <span class="number">0</span>] &gt; <span class="number">0</span>) <span class="comment"># 深度必须大于0（在相机前面，不能在脑后）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. 计算重叠率：有多少点落在了这帧历史图像里？</span></span><br><span class="line">    percent_inside = mask.<span class="built_in">sum</span>()/projected_pts.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>注：这里的历史关键帧是每隔5帧选取一个，另外历史关键帧小于5个时不会触发这里关键帧的选择<br>在script/splatam.py中的Mapping阶段：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add frame to keyframe list</span></span><br><span class="line"><span class="comment"># 这里的 time_idx 是 4</span></span><br><span class="line"><span class="comment"># config[&#x27;keyframe_every&#x27;] 是 5</span></span><br><span class="line"><span class="keyword">if</span> ((time_idx == <span class="number">0</span>) <span class="keyword">or</span> ((time_idx+<span class="number">1</span>) % config[<span class="string">&#x27;keyframe_every&#x27;</span>] == <span class="number">0</span>) ...):</span><br><span class="line">    <span class="comment"># (4 + 1) % 5 == 0，条件成立！</span></span><br><span class="line">    keyframe_list.append(curr_keyframe)  &lt;-- Frame <span class="number">4</span> 在这里被永久存入了历史库</span><br></pre></td></tr></table></figure><h4 id="筛选与随机选择"><a href="#筛选与随机选择" class="headerlink" title="筛选与随机选择"></a>筛选与随机选择</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 先按重叠度从高到低排序 (虽然这一步在后面被随机打乱削弱了，但在逻辑上是先找最好的)</span></span><br><span class="line">list_keyframe = <span class="built_in">sorted</span>(list_keyframe, key=<span class="keyword">lambda</span> i: i[<span class="string">&#x27;percent_inside&#x27;</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 剔除那些完全没重叠的 (percent &gt; 0)</span></span><br><span class="line">selected_keyframe_list = [ ... <span class="keyword">if</span> keyframe_dict[<span class="string">&#x27;percent_inside&#x27;</span>] &gt; <span class="number">0.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 【关键】随机打乱并取前 k 个</span></span><br><span class="line">selected_keyframe_list = <span class="built_in">list</span>(np.random.permutation(np.array(selected_keyframe_list))[:k])</span><br></pre></td></tr></table></figure><p>注：这里为什么要随机打乱再取？按理说应该选 重叠度最高的 k 帧，但如果只选最高的，往往选出来的都是最近的那几帧（因为刚才走过，重叠度肯定最高），而随机打乱并从所有有重叠的帧里选，可以让系统有机会选中很久以前的帧（只要它和当前有重叠）。这对于<strong>回环检测（Loop Closure）</strong>非常重要——即使是 5 分钟前路过的地方，也有机会被选进来一起优化，从而消除累积误差。</p><h3 id="splatam-py-add-new-gaussians"><a href="#splatam-py-add-new-gaussians" class="headerlink" title="splatam.py/add_new_gaussians()"></a>splatam.py/add_new_gaussians()</h3><h4 id="在当前画面中，寻找哪些地方是“空的”或者“画错了的”"><a href="#在当前画面中，寻找哪些地方是“空的”或者“画错了的”" class="headerlink" title="在当前画面中，寻找哪些地方是“空的”或者“画错了的”"></a>在当前画面中，寻找哪些地方是“空的”或者“画错了的”</h4><ol><li>不透明度检查 (Silhouette Check)</li><li>深度检查 (Depth Check)</li></ol><h4 id="反投影"><a href="#反投影" class="headerlink" title="反投影"></a>反投影</h4><p>确定了位置后，把这些 2D 像素变回 3D 点</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_pt_cld, mean3_sq_dist = get_pointcloud(..., mask=non_presence_mask, ...)</span><br></pre></td></tr></table></figure><p>一、 输入</p><ul><li><p>curr_data[‘im’]：当前帧颜色（给新球上色）。</p></li><li><p>curr_data[‘depth’]：当前帧深度（决定新球在 3D 空间的 Z 轴位置）。</p></li><li><p>curr_w2c：当前相机位姿（把点从相机坐标系转回世界坐标系）。</p></li></ul><p>二、 动作</p><p>利用相机内参和深度值，把 Mask 为 True 的像素反向投射回 3D 空间</p><p>三、 输出</p><p>new_pt_cld: 一批全新的 3D 坐标点 $(x, y, z)$</p><h4 id="分配高斯球的属性，然后合并到总地图中"><a href="#分配高斯球的属性，然后合并到总地图中" class="headerlink" title="分配高斯球的属性，然后合并到总地图中"></a>分配高斯球的属性，然后合并到总地图中</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 初始化参数 (给新点分配颜色、大小、旋转)</span></span><br><span class="line">new_params = initialize_new_params(new_pt_cld, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 合并到总参数 (Cat)</span></span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> new_params.items():</span><br><span class="line">    <span class="comment"># 把新参数拼接到老参数后面</span></span><br><span class="line">    params[k] = torch.nn.Parameter(torch.cat((params[k], v), dim=<span class="number">0</span>).requires_grad_(<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 初始化优化器状态 (给新兵发装备)</span></span><br><span class="line">variables[<span class="string">&#x27;means2D_gradient_accum&#x27;</span>] = torch.zeros(...) <span class="comment"># 梯度累计清零</span></span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></table></figure><h2 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h2><h3 id="Final-Average-ATE-RMSE"><a href="#Final-Average-ATE-RMSE" class="headerlink" title="Final Average ATE RMSE"></a>Final Average ATE RMSE</h3><p>全称：Absolute Trajectory Error (绝对轨迹误差) - Root Mean Square Error (均方根误差)<br>含义：衡量“电脑算出来的相机位置”和“真实相机位置”平均差了多远</p><h3 id="以下三个为一组（评价建出来的图，渲染成照片后，跟真实照片像不像的参数）"><a href="#以下三个为一组（评价建出来的图，渲染成照片后，跟真实照片像不像的参数）" class="headerlink" title="以下三个为一组（评价建出来的图，渲染成照片后，跟真实照片像不像的参数）"></a>以下三个为一组（评价建出来的图，渲染成照片后，跟真实照片像不像的参数）</h3><h4 id="Average-PSNR"><a href="#Average-PSNR" class="headerlink" title="Average PSNR"></a>Average PSNR</h4><p>全称：Peak Signal-to-Noise Ratio (峰值信噪比)<br>含义：像素级别的相似度。数值越大越好</p><h4 id="Average-MS-SSIM"><a href="#Average-MS-SSIM" class="headerlink" title="Average MS-SSIM"></a>Average MS-SSIM</h4><p>全称：Multi-Scale Structural Similarity Index (多尺度结构相似性)<br>含义：它比 PSNR 更聪明，它看重“结构”和“纹理”是否清晰。范围是 0~1，越接近 1 越好</p><h4 id="Average-LPIPS"><a href="#Average-LPIPS" class="headerlink" title="Average LPIPS"></a>Average LPIPS</h4><p>全称：Learned Perceptual Image Patch Similarity (学习感知图像块相似度)<br>含义：这是一个 AI 打分器（模仿人类视觉），数值越低越好（0 表示一模一样）</p><h3 id="Average-Depth-RMSE"><a href="#Average-Depth-RMSE" class="headerlink" title="Average Depth RMSE"></a>Average Depth RMSE</h3><p>含义：衡量建出来的 3D 模型表面，距离相机的深浅对不对。越小越好</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.liiz.top">啊可恶</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.liiz.top/2026/01/29/SplaTAM/">https://blog.liiz.top/2026/01/29/SplaTAM/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.liiz.top" target="_blank">啊可恶的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/3DGS/">3DGS</a></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2026/01/29/GaussianUpdate/" title="GaussianUpdate"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">GaussianUpdate</div></div><div class="info-2"><div class="info-item-1">流程一、 全局外观更新全局外观模型：为了对光照引起的全局表观变化进行建模，使用一个4D哈希网格H和一个微小的MLP F作为全局表观模型来推断高斯图元上不同时刻的增量缩放和球谐性质在Layout - Invariant区域进行外观更新：一般来说，全局光照主导了布局不变区域(即没有任何几何变化的静态区域)的外观变化。在第一阶段，我们的方法专注于通过单独优化4D哈希网格来更新这些变化。为了避免场景中可能出现的新物体或移除物体带来的影响，我们设计了一种鲁棒的方法来确定布局不变区域。具体来说，假设It f是新捕获的图像，我们可以用It f的相机姿态和先前的神经模型来渲染It - 1 f。那么对于这对对应的框架{ It f，It - 1f }，我们可以从一个基础模型SAM中得到它们的实例分割掩码{ St f，St - 1f }。 进一步，我们可以从{ St f，St-1 f }中计算相应实例之间的交并比( Intersection over Union，IoU )得分。在t和t - 1两个时间步Io U得分都较高的布局不变区域将被掩膜成{ Mtf，Mt-1f }。在当前时间步t，一个最终的布...</div></div></div></a><a class="pagination-related" href="/2026/01/29/SpatiaLLM/" title="SpatiaLLM"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">SpatiaLLM</div></div><div class="info-2"><div class="info-item-1">.vscode文件夹虽然 launch.json 文件位于 .vscode 文件夹里，但 VS Code 调试器默认的工作目录 (Current Working Directory, CWD)是你的项目根目录（也就是你用 VS Code 打开的那个最外层文件夹），而不是 .vscode 文件夹 Step Over、Step Into、Step OutStep Over (单步跳过):调试主函数时，调试器不会带你进入中间调用的函数内部,当你确信被调用函数是没问题的时候用Step Into (单步调试 / 进入)： 遇到被调用函数会进入函数内部Step Out (单步跳出)：点击后，它会立即执行完当前被调用函数剩余的所有代码，然后直接跳回到主函数中调用它的地方的下一行 Prompt 长什么样1prompt = &#x27;&lt;|point_start|&gt;&lt;|point_pad|&gt;&lt;|point_end|&gt;Detect walls, doors, windows, boxes. The reference code is as followed: @d...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8C%963DGS"><span class="toc-number">1.1.</span> <span class="toc-text">简化3DGS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E5%BE%AE%E6%B8%B2%E6%9F%93"><span class="toc-number">1.2.</span> <span class="toc-text">可微渲染</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SLAM%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.3.</span> <span class="toc-text">SLAM系统</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.</span> <span class="toc-text">总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-1%EF%BC%9A3D-%E9%AB%98%E6%96%AF%E7%90%83%E7%9A%84%E5%AE%9A%E4%B9%89-The-Atom"><span class="toc-number">2.1.</span> <span class="toc-text">公式 1：3D 高斯球的定义 (The Atom)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-2%EF%BC%9A%E5%8F%AF%E5%BE%AE%E6%B8%B2%E6%9F%93-%E9%A2%9C%E8%89%B2-The-Painter"><span class="toc-number">2.2.</span> <span class="toc-text">公式 2：可微渲染 - 颜色 (The Painter)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-3%EF%BC%9A3D-%E5%88%B0-2D-%E7%9A%84%E6%8A%95%E5%BD%B1-The-Lens"><span class="toc-number">2.3.</span> <span class="toc-text">公式 3：3D 到 2D 的投影 (The Lens)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-4%EF%BC%9A%E5%8F%AF%E5%BE%AE%E6%B8%B2%E6%9F%93-%E6%B7%B1%E5%BA%A6-The-Ruler"><span class="toc-number">2.4.</span> <span class="toc-text">公式 4：可微渲染 - 深度 (The Ruler)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-5%EF%BC%9A%E8%BD%AE%E5%BB%93%E6%8E%A9%E8%86%9C-%E5%8F%AF%E8%A7%81%E5%BA%A6-The-Scout"><span class="toc-number">2.5.</span> <span class="toc-text">公式 5：轮廓掩膜 &#x2F; 可见度 (The Scout)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-6%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8D%8A%E5%BE%84-The-Seed"><span class="toc-number">2.6.</span> <span class="toc-text">公式 6：初始化半径 (The Seed)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F-8%EF%BC%9A%E7%9B%B8%E6%9C%BA%E8%BF%BD%E8%B8%AA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-The-Judge"><span class="toc-number">2.7.</span> <span class="toc-text">公式 8：相机追踪损失函数 (The Judge)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">3.</span> <span class="toc-text">代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scripts-splatam-py"><span class="toc-number">3.1.</span> <span class="toc-text">scripts&#x2F;splatam.py</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#get-loss"><span class="toc-number">3.1.1.</span> <span class="toc-text">get_loss()</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#transform-to-frame"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">transform_to_frame()</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%81%92%E9%80%9F%E8%BF%90%E5%8A%A8%E6%A8%A1%E5%9E%8B-initialize-camera-pose-%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.</span> <span class="toc-text">恒速运动模型(initialize_camera_pose 函数)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B3%E7%A7%BB"><span class="toc-number">3.2.1.</span> <span class="toc-text">平移</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%8B%E8%BD%AC"><span class="toc-number">3.2.2.</span> <span class="toc-text">旋转</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#slam-external-py-prune-gaussians"><span class="toc-number">3.3.</span> <span class="toc-text">slam_external.py&#x2F;prune_gaussians()</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8"><span class="toc-number">3.3.1.</span> <span class="toc-text">作用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E6%97%B6%E5%89%AA%E6%9E%9D"><span class="toc-number">3.3.2.</span> <span class="toc-text">定时剪枝</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%89%E6%9D%A1%E4%BB%B6%E7%AD%9B%E9%80%89"><span class="toc-number">3.3.3.</span> <span class="toc-text">按条件筛选</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E7%BD%AE%E9%80%8F%E6%98%8E%E5%BA%A6"><span class="toc-number">3.3.4.</span> <span class="toc-text">重置透明度</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#slam-external-py-keyframe-selection-overlap"><span class="toc-number">3.4.</span> <span class="toc-text">slam_external.py&#x2F;keyframe_selection_overlap</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8%E5%A4%84"><span class="toc-number">3.4.1.</span> <span class="toc-text">用处</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A6%96%E5%85%88%E4%BB%8E%E5%BD%93%E5%89%8D%E5%B8%A7%E9%87%8C%E9%9A%8F%E6%9C%BA%E6%8C%91%E4%BA%86%E4%B8%80%E4%BA%9B%E2%80%9C%E6%8E%A2%E9%92%88%E2%80%9D%E7%82%B9"><span class="toc-number">3.4.2.</span> <span class="toc-text">首先从当前帧里随机挑了一些“探针”点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%8A%E8%BF%99%E4%BA%9B%E9%80%89%E5%87%BA%E6%9D%A5%E7%9A%84-2D-%E5%83%8F%E7%B4%A0%E7%82%B9%EF%BC%8C%E5%8F%98%E6%88%90-3D-%E4%B8%96%E7%95%8C%E5%9D%90%E6%A0%87%E7%82%B9"><span class="toc-number">3.4.3.</span> <span class="toc-text">把这些选出来的 2D 像素点，变成 3D 世界坐标点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%BF%E7%9D%80%E8%BF%99%E4%BA%9B-3D-%E4%B8%96%E7%95%8C%E7%82%B9%EF%BC%8C%E5%8E%BB%E8%AF%95%E6%8E%A2%E6%AF%8F%E4%B8%80%E4%B8%AA%E5%8E%86%E5%8F%B2%E5%85%B3%E9%94%AE%E5%B8%A7%EF%BC%8C%E7%9C%8B%E7%9C%8B%E5%8E%86%E5%8F%B2%E5%B8%A7%E7%9A%84%E7%9B%B8%E6%9C%BA%E8%83%BD%E7%9C%8B%E5%88%B0%E5%A4%9A%E5%B0%91%E7%82%B9"><span class="toc-number">3.4.4.</span> <span class="toc-text">拿着这些 3D 世界点，去试探每一个历史关键帧，看看历史帧的相机能看到多少点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AD%9B%E9%80%89%E4%B8%8E%E9%9A%8F%E6%9C%BA%E9%80%89%E6%8B%A9"><span class="toc-number">3.4.5.</span> <span class="toc-text">筛选与随机选择</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#splatam-py-add-new-gaussians"><span class="toc-number">3.5.</span> <span class="toc-text">splatam.py&#x2F;add_new_gaussians()</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%BD%93%E5%89%8D%E7%94%BB%E9%9D%A2%E4%B8%AD%EF%BC%8C%E5%AF%BB%E6%89%BE%E5%93%AA%E4%BA%9B%E5%9C%B0%E6%96%B9%E6%98%AF%E2%80%9C%E7%A9%BA%E7%9A%84%E2%80%9D%E6%88%96%E8%80%85%E2%80%9C%E7%94%BB%E9%94%99%E4%BA%86%E7%9A%84%E2%80%9D"><span class="toc-number">3.5.1.</span> <span class="toc-text">在当前画面中，寻找哪些地方是“空的”或者“画错了的”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E6%8A%95%E5%BD%B1"><span class="toc-number">3.5.2.</span> <span class="toc-text">反投影</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E9%AB%98%E6%96%AF%E7%90%83%E7%9A%84%E5%B1%9E%E6%80%A7%EF%BC%8C%E7%84%B6%E5%90%8E%E5%90%88%E5%B9%B6%E5%88%B0%E6%80%BB%E5%9C%B0%E5%9B%BE%E4%B8%AD"><span class="toc-number">3.5.3.</span> <span class="toc-text">分配高斯球的属性，然后合并到总地图中</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">4.</span> <span class="toc-text">评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Final-Average-ATE-RMSE"><span class="toc-number">4.1.</span> <span class="toc-text">Final Average ATE RMSE</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A5%E4%B8%8B%E4%B8%89%E4%B8%AA%E4%B8%BA%E4%B8%80%E7%BB%84%EF%BC%88%E8%AF%84%E4%BB%B7%E5%BB%BA%E5%87%BA%E6%9D%A5%E7%9A%84%E5%9B%BE%EF%BC%8C%E6%B8%B2%E6%9F%93%E6%88%90%E7%85%A7%E7%89%87%E5%90%8E%EF%BC%8C%E8%B7%9F%E7%9C%9F%E5%AE%9E%E7%85%A7%E7%89%87%E5%83%8F%E4%B8%8D%E5%83%8F%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%89"><span class="toc-number">4.2.</span> <span class="toc-text">以下三个为一组（评价建出来的图，渲染成照片后，跟真实照片像不像的参数）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Average-PSNR"><span class="toc-number">4.2.1.</span> <span class="toc-text">Average PSNR</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Average-MS-SSIM"><span class="toc-number">4.2.2.</span> <span class="toc-text">Average MS-SSIM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Average-LPIPS"><span class="toc-number">4.2.3.</span> <span class="toc-text">Average LPIPS</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Average-Depth-RMSE"><span class="toc-number">4.3.</span> <span class="toc-text">Average Depth RMSE</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"></div></div><div id="footer-animal"><div class="animal-wall"></div><img class="animal" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.meimolihan.eu.org/hexo/img/color.avif" alt="动物" onerror='this.onerror=null,this.src="/img/404.jpg"'></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight,500)"><i class="fas fa-arrow-down"></i></button></div></div><div><script src="/js/utils.js?v=5.5.3"></script><script src="/js/main.js?v=5.5.3"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.2.0/instantpage.min.js" type="module"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/19.1.3/lazyload.iife.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.js"></script><div class="js-pjax"></div><script src="https://liiz-blog.oss-cn-shenzhen.aliyuncs.com/js/live2d.min.js"></script><script>var timer=setInterval(function(){"undefined"!=typeof OML2D&&(clearInterval(timer),OML2D.loadOml2d({dockedPosition:"left",menus:{disable:!0},models:[{path:"https://liiz-blog.oss-cn-shenzhen.aliyuncs.com/live2d_models/yileina/LSS.model3.json",position:[0,150],scale:.4,stageStyle:{height:500}}]}))},50)</script><script src="https://cdnjs.cloudflare.com/ajax/libs/pjax/0.2.8/pjax.min.js" defer></script><script>document.addEventListener('DOMContentLoaded', () => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => {
      try {
        fn()
      } catch (err) {
        console.debug('Pjax callback failed:', err)
      }
    })
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      false
        ? pjax.loadUrl('/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})</script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"></div><hr><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.3"></script></div></div></body></html>